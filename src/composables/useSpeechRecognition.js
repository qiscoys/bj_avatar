import { useConfig } from '@/composables/useConfig'
import VoiceRecognizer from '@/utils/SpeechRecognition.js'
import { useSpeechStore } from '@/stores'

// å…¨å±€æ§åˆ¶ï¼šé˜²æ­¢é‡å¤ç»‘å®šï¼Œæ”¯æŒç»Ÿä¸€ç§»é™¤æ—§ç›‘å¬
let __srListenersAbortController = null

// ğŸ”¥ é¦–æ¬¡å¯åŠ¨æ ‡å¿—ï¼šç”¨äºæ§åˆ¶è¯­éŸ³è¯†åˆ«å¯åŠ¨æ—¶æœº
// åªåœ¨ç¬¬ä¸€æ®µæ¬¢è¿éŸ³é¢‘æ’­æ”¾ç»“æŸåæ‰å¯åŠ¨
let hasFirstStarted = false

export function useSpeechRecognition() {
  const speechStore = useSpeechStore()
  const { config } = useConfig()

  // Store è®¡ç®—å±æ€§
  const isRecording = computed(() => speechStore.recognition.isRecording)
  const isListening = computed(() => speechStore.recognition.isListening)
  const isProcessing = computed(() => speechStore.recognition.isProcessing)
  const currentText = computed(() => speechStore.recognition.currentText)
  const finalText = computed(() => speechStore.recognition.finalText)
  const interimText = computed(() => speechStore.recognition.interimText)
  const confidence = computed(() => speechStore.recognition.confidence)
  const error = computed(() => speechStore.recognition.error)
  const isSupported = computed(() => speechStore.recognition.isSupported)
  const longPress = computed(() => speechStore.longPress)

  // ä¾èµ–ç®¡ç†å™¨
  let avatarState = null
  let ui = null
  let audio = null
  let utils = null
  let recognizer = null
  let uiStore = null
  // é˜²é‡å¤å¤„ç†
  let interimDebounceTimer = null
  let lastInterimTranscript = ''
  // ä¸šåŠ¡æµç¨‹ç”¨æˆ·è¾“å…¥å»é‡ï¼ˆè§„èŒƒåŒ–åçš„æ•°å­—ï¼‰
  const lastBusinessDigitsPushed = ref('')

  // å°†ä¸­æ–‡æ•°å­—ï¼ˆå«å¤§å†™ï¼‰è§„èŒƒåŒ–ä¸ºé˜¿æ‹‰ä¼¯æ•°å­—ï¼Œä»…ä¿ç•™æ•°å­—å­—ç¬¦
  const normalizeToDigits = (text) => {
    const s = String(text || '')
    const map = {
      'é›¶': '0', 'ã€‡': '0', 'â—‹': '0', 'ï¼¯': '0', 'o': '0', 'O': '0',
      'å¹º': '1', 'ä¸€': '1', 'å£¹': '1',
      'äºŒ': '2', 'è´°': '2', 'ä¸¤': '2',
      'ä¸‰': '3', 'å': '3',
      'å››': '4', 'è‚†': '4',
      'äº”': '5', 'ä¼': '5',
      'å…­': '6', 'é™†': '6',
      'ä¸ƒ': '7', 'æŸ’': '7',
      'å…«': '8', 'æŒ': '8',
      'ä¹': '9', 'ç–': '9',
    }
    let out = ''
    for (const ch of s.replace(/\s+/g, '')) {
      if (/\d/.test(ch)) {
        out += ch
      } else if (map[ch]) {
        out += map[ch]
      } else {
        // å¿½ç•¥å•ä½å­—ï¼šå/ç™¾/åƒ/ä¸‡/äº¿ ç­‰ï¼Œé¿å…éé€ä½æ•°å­—å½±å“
      }
    }
    return out
  }
  let lastProcessedText = '' // é˜²é‡å¤ï¼šè®°å½•æœ€åå¤„ç†çš„æ–‡æœ¬

  // æœ¬åœ°çŠ¶æ€
  const isVoiceRecording = ref(false)
  const isLongPressRecording = ref(false)
  const longPressTextBuffer = ref('')
  const isInitialized = ref(false)
  const isConnected = ref(false)
  // å»æ‰æŒç»­è¯†åˆ«æ¨¡å¼ï¼ŒæŒ‰åˆæˆæ’­æ”¾çŠ¶æ€æ§åˆ¶æš‚åœ/æ¢å¤
  const speechSynthesisActive = ref(false) // è¯­éŸ³åˆæˆæ’­æ”¾çŠ¶æ€
  const isSpeaking = ref(false) // æ£€æµ‹åˆ°ç”¨æˆ·æ­£åœ¨è¯´è¯
  const allowInterruption = ref(true) // æ˜¯å¦å…è®¸æ‰“æ–­
  // const recognizedText = ref('')

  // äº‹ä»¶è§¦å‘
  const emitEvent = (eventName) => {
    utils?.eventManager?.emit?.(document, eventName)
  }

  // ç›‘å¬è¯­éŸ³åˆæˆæ’­æ”¾çŠ¶æ€
  const setupSpeechSynthesisListeners = () => {
    // å…ˆç§»é™¤å·²æœ‰ç›‘å¬ï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼Œé¿å…é‡å¤ç»‘å®šå¯¼è‡´äº‹ä»¶è§¦å‘å¤šæ¬¡
    if (__srListenersAbortController) {
      try { __srListenersAbortController.abort() } catch (e) {}
    }
    __srListenersAbortController = new AbortController()
    const signal = __srListenersAbortController.signal

    // ç›‘å¬è¯­éŸ³åˆæˆå¼€å§‹äº‹ä»¶
    document.addEventListener('speechStart', async () => {
      speechSynthesisActive.value = true
      
      // è¯­éŸ³åˆæˆå¼€å§‹æ—¶ä¸å†åœæ­¢è¯†åˆ«ï¼Œè€Œæ˜¯ç»§ç»­è¿è¡Œä»¥æ”¯æŒæ‰“æ–­
      // åªæ¸…ç©ºè¯†åˆ«ç»“æœæ˜¾ç¤ºï¼Œä½†ä¿æŒè¯†åˆ«å™¨è¿è¡Œ
      speechStore.setInterimText('')
      speechStore.setFinalText('')
      speechStore.setCurrentText('')
      speechStore.setConfidence(0)
      speechStore.setRecognitionError(null)
      
      // æ”¯æŒæ‰“æ–­
      if (!isVoiceRecording.value && allowInterruption.value) {
        try {
          await start({ interimResults: true })
        } catch (e) { /* ignore */ }
      }
    }, { signal })

    // ç›‘å¬è¯­éŸ³åˆæˆç»“æŸäº‹ä»¶
    document.addEventListener('speechEnd', async () => {
      speechSynthesisActive.value = false
      // æ¸…ç©ºè¯†åˆ«ç»“æœï¼Œä»¿ç…§ public è¿æ¥é˜¶æ®µé‡ç½®
      speechStore.setInterimText('')
      speechStore.setFinalText('')
      speechStore.setCurrentText('')
      speechStore.setConfidence(0)
      speechStore.setRecognitionError(null)

      // æ¬¢è¿éŸ³é¢‘æ’­æ”¾ç»“æŸåæ‰å¯åŠ¨è¯­éŸ³è¯†åˆ«
      if (!hasFirstStarted) {
        hasFirstStarted = true
        const isAudioPlaying = audio?.isCurrentlyPlaying?.() || false
        if (!isAudioPlaying) {
          try {
            await start({ interimResults: true })
          } catch (e) { /* ignore */ }
        }
        return  // é¦–æ¬¡å¯åŠ¨åè¿”å›ï¼Œä¸æ‰§è¡Œä¸‹é¢çš„é‡å¯é€»è¾‘
      }

      // åç»­çš„éŸ³é¢‘æ’­æ”¾ç»“æŸï¼Œç¡®ä¿è¯†åˆ«ç»§ç»­è¿è¡Œ
      const isAudioPlaying = audio?.isCurrentlyPlaying?.() || false
      // æ£€æŸ¥è¯†åˆ«å™¨çš„å®é™…çŠ¶æ€ï¼Œè€Œä¸ä»…ä»…ä¾èµ–æœ¬åœ°å˜é‡
      const actuallyRecording = recognizer?.isListening || false
      console.log('[è¯­éŸ³è¯†åˆ«] speechEndäº‹ä»¶è§¦å‘ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯', {
        isAudioPlaying,
        actuallyRecording,
        isVoiceRecording: isVoiceRecording.value,
        avatarState: avatarState?.getCurrentState?.()
      })
      
      if (!isAudioPlaying && !actuallyRecording) {
        try {
          console.log('[è¯­éŸ³è¯†åˆ«] éŸ³é¢‘æ’­æ”¾ç»“æŸï¼Œå‡†å¤‡é‡å¯è¯†åˆ«')
          await start({ interimResults: true })
          console.log('[è¯­éŸ³è¯†åˆ«] é‡å¯è¯†åˆ«æˆåŠŸ')
        } catch (e) {
          console.warn('[è¯­éŸ³è¯†åˆ«] é‡å¯è¯­éŸ³è¯†åˆ«å¤±è´¥:', e)
        }
      }
    }, { signal })

    // ç›‘å¬è¯­éŸ³åˆæˆé”™è¯¯äº‹ä»¶
    document.addEventListener('speechError', async () => {
      speechSynthesisActive.value = false
      // æ¸…ç©ºè¯†åˆ«ç»“æœ
      speechStore.setInterimText('')
      speechStore.setFinalText('')
      speechStore.setCurrentText('')
      speechStore.setConfidence(0)
      speechStore.setRecognitionError(null)

      if (!hasFirstStarted) {
        hasFirstStarted = true
      }

      // ç¡®ä¿è¯†åˆ«ç»§ç»­è¿è¡Œ
      if (!isVoiceRecording.value) {
        await start({ interimResults: true })
      }
    }, { signal })
  }

  // åˆå§‹åŒ–è¯†åˆ«å™¨
  const initRecognition = async () => {
    if (recognizer) return true

    recognizer = new VoiceRecognizer()
    await recognizer.init({
      interimResults: true,
      lang: 'zh-CN'
    })

    // äº‹ä»¶ç»‘å®š
    recognizer.on('connected', () => {
      isConnected.value = true
    })

    recognizer.on('disconnected', () => {
      isConnected.value = false
    })

    recognizer.on('start', () => {
      isVoiceRecording.value = true
      speechStore.setRecordingState(true)
      // æ¸…ç©ºç»“æœï¼Œé¿å…å åŠ 
      speechStore.setInterimText('')
      speechStore.setFinalText('')
      speechStore.setCurrentText('')
      speechStore.setConfidence(0)
      emitEvent('speechRecognitionStart')
    })

    recognizer.on('result', ({ final, interim, isFinal, confidence: conf }) => {
      const transcript = final || interim
      console.log('è¯­éŸ³è¯†åˆ«ç»“æœ:', transcript, isFinal ? '(æœ€ç»ˆ)' : '(ä¸­é—´)')
      if (isFinal && final?.trim()) {
        console.log('è¯­éŸ³è¯†åˆ«æœ€ç»ˆç»“æœ:', final.trim())
      }

      // å¦‚æœåœ¨è¯­éŸ³åˆæˆæ’­æ”¾æ—¶æ£€æµ‹åˆ°ç”¨æˆ·è¯´è¯ï¼Œç«‹å³æ‰“æ–­
      if (speechSynthesisActive.value && allowInterruption.value && transcript?.trim()) {
        // åœæ­¢è¯­éŸ³åˆæˆ
        if (window.speechSynthesis) {
          window.speechSynthesis.cancel()
        }
        // è§¦å‘è¯­éŸ³åˆæˆåœæ­¢äº‹ä»¶
        emitEvent('speechSynthesisInterrupted')
        speechSynthesisActive.value = false
        
        // æ¸…ç©ºä¹‹å‰çš„åˆæˆå†…å®¹ï¼Œå‡†å¤‡å¤„ç†ç”¨æˆ·è¾“å…¥
        speechStore.setInterimText('')
        speechStore.setFinalText('')
        speechStore.setCurrentText('')
      }

      if (isLongPressRecording.value) {
        longPressTextBuffer.value = transcript || ''
        speechStore.setInterimText(transcript || '')
        return
      }

      if (isFinal && final?.trim()) {
        // åªåœ¨æœ€ç»ˆç»“æœæ—¶å¤„ç†å’Œå‘é€
        // æ¸…ç†å®æ—¶æ´¾å‘å®šæ—¶å™¨ï¼ˆå¦‚æœæœ‰æœªå®Œæˆçš„ä¸­é—´ç»“æœå¤„ç†ï¼‰
        if (interimDebounceTimer) {
          clearTimeout(interimDebounceTimer)
          interimDebounceTimer = null
        }

        // é˜²é‡å¤ï¼šæ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡ç›¸åŒæˆ–ç›¸ä¼¼çš„æ–‡æœ¬
        const normalizedFinal = final.trim().replace(/[ã€‚ï¼Œï¼ï¼Ÿ\s]+$/g, '') // å»é™¤å°¾éƒ¨æ ‡ç‚¹
        const normalizedLast = lastProcessedText.replace(/[ã€‚ï¼Œï¼ï¼Ÿ\s]+$/g, '')

        if (normalizedFinal !== normalizedLast) {
          lastProcessedText = final.trim()
          onRecognitionComplete(final.trim())
        }

        // æ›´æ–° Store æœ€ç»ˆç»“æœ
        speechStore.setFinalText(final.trim())
        speechStore.setInterimText('')
        speechStore.setConfidence(typeof conf === 'number' ? conf : 0)
      } else {
        // ä¸­é—´ç»“æœï¼šå®æ—¶ä½“ç°åˆ°ç”¨æˆ·å¯¹è¯æ¡†ï¼ˆä¸šåŠ¡æµç¨‹å†…ï¼‰ï¼Œå¹¶æ›´æ–°Store
        speechStore.setInterimText(transcript || '')
        speechStore.setConfidence(typeof conf === 'number' ? conf : 0)

        const curr = (transcript || '').trim()
        if (curr && curr !== lastInterimTranscript) {
          lastInterimTranscript = curr
          if (interimDebounceTimer) clearTimeout(interimDebounceTimer)
          // è½»å¾®é˜²æŠ–ï¼Œé¿å…é¢‘ç¹æ¨é€ä½†ä¿æŒå®æ—¶æ„Ÿ
          interimDebounceTimer = setTimeout(() => {
            updateVoiceDisplay(curr)
          }, 120)
        }
      }
    })

    recognizer.on('end', async () => {
      isVoiceRecording.value = false
      speechStore.setRecordingState(false)
      emitEvent('speechRecognitionEnd')

      // åœ¨æœªæ’­æ”¾åˆæˆéŸ³é¢‘çš„æƒ…å†µä¸‹ï¼Œè‡ªåŠ¨ç»§ç»­è¯†åˆ«
      const isAudioPlaying = audio?.isCurrentlyPlaying?.() || false
      console.log('[è¯­éŸ³è¯†åˆ«] è¯†åˆ«ç»“æŸï¼Œå‡†å¤‡è‡ªåŠ¨é‡å¯', {
        speechSynthesisActive: speechSynthesisActive.value,
        isAudioPlaying,
        avatarState: avatarState?.getCurrentState?.()
      })

      if (!speechSynthesisActive.value && !isAudioPlaying) {
        setTimeout(async () => {
          try {
            await start({ interimResults: true })
            console.log('[è¯­éŸ³è¯†åˆ«] è‡ªåŠ¨é‡å¯æˆåŠŸ')
          } catch (e) {
            console.warn('[è¯­éŸ³è¯†åˆ«] è‡ªåŠ¨é‡å¯å¤±è´¥:', e)
          }
        }, 100)
      }
    })

    recognizer.on('error', async (e) => {
      resetRecordingState()
      emitEvent('speechRecognitionError')

      // éåˆæˆæ’­æ”¾æ—¶å°è¯•è‡ªåŠ¨æ¢å¤è¯†åˆ«
      const isAudioPlaying = audio?.isCurrentlyPlaying?.() || false
      if (!speechSynthesisActive.value && !isAudioPlaying) {
        // æ¸è¿›é‡è¯•ï¼Œé¿å…æœåŠ¡ç«¯çŸ­æš‚ä¸å¯ç”¨é€ æˆçš„ç«‹å³å¤±è´¥
        const delays = [200, 800, 2000]
        const tryRestart = async (i = 0) => {
          try {
            await start({ interimResults: true })
            console.log('[è¯­éŸ³è¯†åˆ«] è‡ªåŠ¨é‡å¯æˆåŠŸ')
          } catch (err) {
            console.warn('[è¯­éŸ³è¯†åˆ«] è‡ªåŠ¨é‡å¯å¤±è´¥:', err)
            if (i < delays.length) {
              setTimeout(() => tryRestart(i + 1), delays[i])
            } else {
              speechStore.setRecognitionError('WebSocketè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡åœ°å€æ˜¯å¦å¯è¾¾')
            }
          }
        }
        tryRestart(0)
      }
    })

    // ç›‘å¬è¯­éŸ³æ£€æµ‹äº‹ä»¶
    recognizer.on('speechstart', () => {
      isSpeaking.value = true
    })

    recognizer.on('speechend', () => {
      isSpeaking.value = false
    })

    isInitialized.value = true
    return true
  }

  // å¼€å§‹è¯†åˆ«
  const start = async (opts = {}) => {
    if (!isInitialized.value) {
      await initRecognition()
    }

    if (isVoiceRecording.value) return false

    // è§¦å‘è¯†åˆ«æµç¨‹å‰ï¼Œæ¸…ç©ºè¯†åˆ«ç»“æœï¼Œé¿å…å åŠ 
    speechStore.setInterimText('')
    speechStore.setFinalText('')
    speechStore.setCurrentText('')
    speechStore.setConfidence(0)
    speechStore.setRecognitionError(null)

    // é‡ç½®é˜²é‡å¤æ ‡è®°ï¼Œå¼€å¯æ–°çš„è¯†åˆ«ä¼šè¯
    lastProcessedText = ''

    await recognizer.start({
      interimResults: opts.interimResults ?? true,
      lang: 'zh-CN'
    })
    return true
  }

  // åœæ­¢è¯†åˆ«
  const stop = async () => {
    if (recognizer && isVoiceRecording.value) {
      await recognizer.stop()
    }
    resetRecordingState()
  }

  // é•¿æŒ‰å½•éŸ³å¼€å§‹
  const startLongPressRecording = async () => {
    speechStore.startLongPress()
    speechStore.setInterimText('')
    longPressTextBuffer.value = ''
    isLongPressRecording.value = true

    const success = await start({ interimResults: true })
    if (!success) {
      speechStore.endLongPress()
      isLongPressRecording.value = false
    }
  }

  // é•¿æŒ‰å½•éŸ³ç»“æŸ
  const endLongPressRecording = async () => {
    if (!isLongPressRecording.value) return

    speechStore.endLongPress()
    isLongPressRecording.value = false
    await stop()

    const result = recognizer?.getResult?.() || {}
    const text = (result.final || result.interim || longPressTextBuffer.value || '').trim()
    if (text) {
      onRecognitionComplete(text)
    }

    speechStore.setInterimText('')
  }

  // è¯†åˆ«å®Œæˆå¤„ç†ï¼ˆä»…æœ€ç»ˆç»“æœï¼‰
  const onRecognitionComplete = (transcript) => {
    const norm = String(transcript || '').trim().replace(/\s+/g, '')
    if (!norm) return

    updateVoiceDisplay(transcript)
    // ç»“æŸç”¨æˆ·æµå¼å¯¹è¯é¡¹
    try { avatarState?.finishUserStreamingDialogue?.() } catch {}
    processVoiceInput(transcript)
  }

  // å¤„ç†è¯­éŸ³è¾“å…¥
  const processVoiceInput = (transcript) => {
    const isActionMode = ui?.actionStatus?.value

    if (avatarState && !isActionMode) {
      if (avatarState.handleVoiceInput?.(transcript)) {
        return
      }
    }
    handleLegacyVoiceInput(transcript)
  }

  // æ›´æ–°æ˜¾ç¤º
  const updateVoiceDisplay = (transcript) => {
    const isInBusiness = avatarState?.getCurrentState?.() === config?.states?.BUSINESS_PROCESSING
      && avatarState?.isProcessingBusinessFlow?.()

    if (isInBusiness && avatarState?.pushUserDialogue) {
      // åœ¨ä¸šåŠ¡æµç¨‹ä¸­ï¼šè‹¥åŒ…å«æ•°å­—åˆ™ä»…æ¨é€æ•°å­—ï¼›å¦åˆ™æ¨é€åŸå§‹æ–‡æœ¬
      // const digits = normalizeToDigits(transcript)
      // if (digits) {
      //   if (digits !== lastBusinessDigitsPushed.value) {
      //     avatarState.pushUserDialogue(digits)
      //     lastBusinessDigitsPushed.value = digits
      //   }
      // } else {
        avatarState.pushUserDialogue(transcript)
      // }
    } else {
      speechStore.setCurrentText(transcript)
    }
  }

  // é‡ç½®çŠ¶æ€
  const resetRecordingState = () => {
    speechStore.setRecordingState(false)
    speechStore.endLongPress()
    speechStore.setInterimText('')
    isLongPressRecording.value = false
    lastProcessedText = '' // é‡ç½®é˜²é‡å¤æ ‡è®°
  }

  // ===== ä¼ ç»Ÿè¯­éŸ³å¤„ç† =====
  const handleLegacyVoiceInput = (transcript) => {
    const cleanText = transcript.toLowerCase().replace(/[ï¼Œã€‚ï¼ï¼Ÿ\s]/g, '')

    if (handleDanceCommand(cleanText)) return
    if (handleAvatarSwitchCommands(cleanText)) return
    if (handleActionLibraryCommands(cleanText)) return
    if (handleActionSwitchCommands(cleanText)) return
    if (handleExitCommands(cleanText)) return
  }

  // å½¢è±¡åˆ‡æ¢æŒ‡ä»¤
  const handleAvatarSwitchCommands = (cleanText) => {
    // è·å–æ‰€æœ‰å¯ç”¨å½¢è±¡é…ç½®
    const avatars = config.avatars || {}

    // æ£€æŸ¥æ˜¯å¦åŒ…å«"åˆ‡æ¢å½¢è±¡"å…³é”®è¯ï¼ˆæ‰“å¼€å¼¹çª—ï¼‰
    const openModalKeywords = ['åˆ‡æ¢å½¢è±¡', 'æ¢å½¢è±¡', 'æ›´æ¢å½¢è±¡','å½¢è±¡åˆ‡æ¢',]
    const shouldOpenModal = openModalKeywords.some(k => cleanText.includes(k))

    // æ£€æŸ¥å¼¹çª—æ˜¯å¦å·²æ‰“å¼€
    const isModalOpen = uiStore?.showActionList || false

    // ç¬¬ä¸€æ­¥ï¼šå¦‚æœè¯´"åˆ‡æ¢å½¢è±¡"ä¸”å¼¹çª—æœªæ‰“å¼€ï¼Œåˆ™æ‰“å¼€å¼¹çª—
    if (shouldOpenModal && !isModalOpen) {
      if (uiStore?.showPopup) {
        uiStore.showPopup('actionList')
      }
      return true
    }

    // ç¬¬äºŒæ­¥ï¼šå¦‚æœå¼¹çª—å·²æ‰“å¼€ï¼Œæ£€æŸ¥æ˜¯å¦åŒ¹é…å½¢è±¡åç§°
    if (isModalOpen) {
      // éå†æ‰€æœ‰å½¢è±¡é…ç½®ï¼ŒåŠ¨æ€åŒ¹é…
      for (const [avatarId, avatarConfig] of Object.entries(avatars)) {
        const avatarName = avatarConfig.name || ''
        const avatarNameEn = avatarConfig.nameEn || ''

        // æ„å»ºåŒ¹é…å…³é”®è¯åˆ—è¡¨
        const matchKeywords = [
          avatarName,
          avatarNameEn,
          avatarId
        ].filter(Boolean)

        // æ£€æŸ¥æ˜¯å¦åŒ¹é…å½¢è±¡åç§°æˆ–ID
        const matchesName = matchKeywords.some(keyword =>
          cleanText.includes(keyword.toLowerCase())
        )

        if (matchesName) {
          // åˆ‡æ¢å½¢è±¡
          if (avatarState?.setCurrentAvatar) {
            avatarState.setCurrentAvatar(avatarId)
          }
          // å…³é—­å¼¹çª—
          if (uiStore?.hidePopup) {
            uiStore.hidePopup('actionList')
          }

          ui?.returnToMain?.()
          return true
        }
      }
    }

    return false
  }

  // åŠ¨ä½œåº“æŒ‡ä»¤
  const handleActionLibraryCommands = (cleanText) => {
    const keywords = ['åŠ¨ä½œåº“', 'åŠ¨ä½œé…·', 'åŠ¨ä½œ', 'åŠ¨åº“', 'åŠ¨ä½œåˆ—è¡¨', 'åˆ‡æ¢åŠ¨ä½œ']
    if (!keywords.some(k => cleanText.includes(k))) return false

    if (typeof ui?.handleActionChange === 'function') {
      ui.handleActionChange()
    } else {
      avatarState?.enableManualActionMode?.()

      if (utils?.eventManager) {
        const uiChecker = utils.eventManager.getStateChecker('ui')
        if (uiChecker?.exists?.()) {
          if (uiChecker.hasMethod?.('pauseWelcomeActivities')) {
            ui?.pauseWelcomeActivities?.()
          }
          ui?.setActionStatus?.(true)
        }
      }
    }
    return true
  }

  // åŠ¨ä½œåˆ‡æ¢æŒ‡ä»¤
  const handleActionSwitchCommands = (cleanText) => {
    const actionMapping = typeof ui?.getActionMapping === 'function'
      ? ui.getActionMapping()
      : {}

    const cnMap = {
      action: 'åŠ¨ä½œ', sayHi: 'æ‰“æ‹›å‘¼', welcome: 'æ¬¢è¿', speak: 'è¯´è¯',
      listen: 'è†å¬', dance: 'è·³èˆ', finishing: 'æˆåŠŸ', heart: 'ç¬”èŠ¯',
      happy: 'å¼€å¿ƒ', disappointed: 'å¤±æœ›', submitInvoice: 'å¼€å‘ç¥¨',
      queryData: 'æŸ¥è¯¢æ•°æ®', introduceProd: 'ä»‹ç»äº§å“', tel: 'æ‰‹æœºå·',
      telConfirm: 'å·ç ç¡®è®¤',
    }

    for (const [action, chinese] of Object.entries(cnMap)) {
      if (actionMapping[action] && (cleanText.includes(chinese) || cleanText.includes(action))) {
        ui?.switchAction?.(action)
        if (ui?.currentAction) {
          ui.currentAction.value = action
        }
        return true
      }
    }
    return false
  }

  // é€€å‡ºæŒ‡ä»¤
  const handleExitCommands = (cleanText) => {
    const exitWords = ['é€€å‡º', 'è¿”å›ä¸»é¡µ', 'è¿”å›ä¸»é¡µé¢', 'å›åˆ°ä¸»é¡µ','ç»“æŸå¯¹è¯']
    if (!exitWords.some(word => cleanText.includes(word))) return false

    ui?.returnToMain?.()
    return true
  }

  // è·³èˆæŒ‡ä»¤
  const handleDanceCommand = (cleanText) => {
    const danceKeywords = ['å°ç¿¼è¯·è·³ä¸ªèˆ', 'å°ç¿¼è·³ä¸ªèˆ', 'è·³ä¸ªèˆ', 'è¯·è·³èˆ', 'è·³èˆå§']
    if (!danceKeywords.some(k => cleanText.includes(k))) return false

    // ğŸ”¥ å¯ç”¨æ‰‹åŠ¨æ¨¡å¼ï¼Œé˜²æ­¢ speechEnd äº‹ä»¶è‡ªåŠ¨åˆ‡æ¢åŠ¨ä½œ
    if (avatarState?.setManualMode) {
      avatarState.setManualMode(true)
    }

    // å…³é—­è¯­éŸ³è¯†åˆ«
    stop()

    // ç›´æ¥è®¾ç½®åŠ¨ä½œå’ŒUIï¼Œä¸è§¦å‘è‡ªåŠ¨éŸ³é¢‘æ’­æ”¾
    try {
      if (uiStore?.forceSetCurrentAction) {
        uiStore.forceSetCurrentAction('danceStatus')
      }
    } catch {}

    if (avatarState?.state?.value) {
      avatarState.state.value.action = 'danceStatus'
    }

    // æ’­æ”¾è·³èˆéŸ³é¢‘
    const danceAudio = config.audios?.danceStatus
    if (danceAudio && audio?.playCustomAudio) {
      // æ˜¾ç¤ºéŸ³ä¹ç¬¦å·
      showMusicNote()

      // æ’­æ”¾éŸ³é¢‘ï¼ŒéŸ³é¢‘ç»“æŸåå›åˆ°æ¬¢è¿çŠ¶æ€
      audio.playCustomAudio(danceAudio, () => {
        // éšè—éŸ³ä¹ç¬¦å·
        hideMusicNote()

        // ğŸ”¥ ç¦ç”¨æ‰‹åŠ¨æ¨¡å¼ï¼Œæ¢å¤è‡ªåŠ¨åŠ¨ä½œåˆ‡æ¢
        if (avatarState?.setManualMode) {
          avatarState.setManualMode(false)
        }

        // é€€å‡º
        handleExitCommands('é€€å‡º')
      })
    }

    return true
  }

  // æ˜¾ç¤ºéŸ³ä¹ç¬¦å·
  const showMusicNote = () => {
    const musicNote = document.getElementById('music-note-animation')
    if (musicNote) {
      musicNote.style.display = 'block'
    }
  }

  // éšè—éŸ³ä¹ç¬¦å·
  const hideMusicNote = () => {
    const musicNote = document.getElementById('music-note-animation')
    if (musicNote) {
      musicNote.style.display = 'none'
    }
  }

  // æ‰“æ–­æ§åˆ¶æ–¹æ³•
  const setInterruptionEnabled = (enabled) => {
    allowInterruption.value = enabled
  }

  const isInterruptionEnabled = () => allowInterruption.value

  // é”€æ¯
  const destroy = async () => {
    await stop()
    audio?.stopCurrentAudio?.()

    if (recognizer) {
      await recognizer.destroy()
      recognizer = null
    }

    isInitialized.value = false
  }

  // åˆå§‹åŒ–æ—¶è®¾ç½®è¯­éŸ³åˆæˆç›‘å¬å™¨
  onMounted(() => {
    setupSpeechSynthesisListeners()
    initRecognition()
      .then(() => { /* initialized */ })
      .catch(() => { /* å¿½ç•¥åˆå§‹åŒ–é”™è¯¯ */ })
  })

  onUnmounted(destroy)

  return {
    // çŠ¶æ€
    isVoiceRecording: readonly(isVoiceRecording),
    isConnected: readonly(isConnected),
    isLongPressRecording: () => isLongPressRecording.value,
    longPressTextBuffer: readonly(longPressTextBuffer),
    isInitialized: readonly(isInitialized),
    speechSynthesisActive: readonly(speechSynthesisActive),
    isSpeaking: readonly(isSpeaking),
    allowInterruption: readonly(allowInterruption),
    // recognizedText: readonly(recognizedText),

    // Store çŠ¶æ€
    isRecording,
    isListening,
    isProcessing,
    currentText,
    finalText,
    interimText,
    confidence,
    error,
    isSupported,
    longPress,

    // æ–¹æ³•
    initRecognition,
    start,
    stop,
    startLongPressRecording,
    endLongPressRecording,
    stopRecording: () => isLongPressRecording.value ? endLongPressRecording() : stop(),
    isRecording: () => isVoiceRecording.value,
    setInterruptionEnabled,
    isInterruptionEnabled,
    destroy,

    // ä¾èµ–æ³¨å…¥
    setManagers: (injectedAvatarState, injectedUi, injectedAudio, injectedUtils, injectedUiStore) => {
      avatarState = injectedAvatarState
      ui = injectedUi
      audio = injectedAudio
      utils = injectedUtils
      uiStore = injectedUiStore
    },
  }
}
